\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{natbib}

\title{Frontier Large Language Models for Ancient Language Understanding:\\A Comprehensive Multi-Language, Multi-Modal Study}

\author{
    ClayVoices Research Team\\
    \texttt{contact@clayvoices.org}
}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
We present the first comprehensive evaluation of frontier Large Language Models (LLMs) on ancient language tasks spanning multiple writing systems and modalities. Through systematic experiments on Sumerian and Egyptian translation using Claude Opus 4.5, GPT-5.2, and Gemini 3, plus vision-based hieroglyph recognition, we demonstrate that in-context learning can achieve state-of-the-art performance on certain ancient language benchmarks without any training. Our best results include 22.04 BLEU on Sumerian-English translation (exceeding the 21.6 BLEU baseline by 2\%), 35.69 BLEU on Egyptian hieroglyphic translation (84.5\% of recent SOTA), and 100\% accuracy on Egyptian hieroglyph visual recognition with 10 examples. We establish optimal shot counts (~1000), analyze persona-based prompting effects across languages, investigate monolingual context priming, and demonstrate that in-context learning effectiveness varies significantly by language family and recency of specialized baselines.
\end{abstract}

\section{Introduction}
\label{sec:intro}

Ancient languages represent critical links to human cultural and historical heritage, yet translation and analysis remain bottlenecked by scarcity of expert translators and traditional computational approaches requiring extensive training data. Recent advances in Large Language Models demonstrate remarkable few-shot learning capabilities on modern languages, raising the question: can frontier LLMs handle ancient language understanding tasks through pure in-context learning?

We address this through comprehensive experiments across multiple ancient writing systems:
- Sumerian cuneiform (language isolate, 3100-2000 BCE)
- Egyptian hieroglyphics (Afro-Asiatic, 3000 BCE-300 CE)
- Visual hieroglyph recognition (cross-modal capabilities)

\subsection{Contributions}
\label{subsec:contributions}

\begin{enumerate}
    \item \textbf{State-of-the-art on Sumerian}: 22.04 BLEU exceeds previous 21.6 BLEU baseline
    \item \textbf{Strong Egyptian performance}: 35.69 BLEU (84.5\% of recent specialized pipeline SOTA)
    \item \textbf{Perfect vision recognition}: 100\% accuracy on Egyptian hieroglyphs with 10 visual examples
    \item \textbf{Comprehensive learning curves}: 0-2000 shot experiments across two languages
    \item \textbf{Multi-modal evaluation}: Text translation + vision recognition
    \item \textbf{Novel findings}: Monolingual priming effects, optimal shot counts, persona-based prompting analysis
    \item \textbf{Production infrastructure}: Open-source benchmark supporting multiple ancient languages
\end{enumerate}

\section{Related Work}
\label{sec:related}

\subsection{Neural Machine Translation for Ancient Languages}

\textbf{Sumerian:} \cite{punia2020sumerian} established the first NMT baseline with 21.6 BLEU using OpenNMT Transformer on 8,116 parallel sentence pairs.

\textbf{Akkadian:} \cite{gutherz2023akkadian} achieved 37.47 BLEU on transliteration-based translation. \cite{jones2025akkadian} recently demonstrated 47.8 BLEU using fine-tuned Mistral 7B, showing the value of pre-training on related Semitic languages.

\textbf{Egyptian Hieroglyphics:} \cite{nasser2025hieroglyphtranslator} achieved 42.22 BLEU using a hierarchical pipeline (ResNet50 glyph classification → Gardiner code mapping → OpenNMT translation) on the EgyptianTranslation dataset.

\subsection{Vision-Based Ancient Script Recognition}

\cite{wang2024hust} created the HUST-OBC dataset with 140,053 Oracle Bone Script images. \cite{piggott2025hieroglyphs} demonstrated CNN-based hieroglyph classification achieving 96\%+ accuracy on individual glyphs.

\subsection{LLM Few-Shot Learning}

\cite{brown2020language} demonstrated that GPT-3 exhibits strong few-shot learning on modern NLP tasks. We extend this to ancient languages, testing whether in-context learning generalizes to low-resource historical languages.

\section{Methodology}
\label{sec:methods}

\subsection{Datasets}
\label{subsec:datasets}

\textbf{Sumerian-English:} CDLI Machine Translation repository \cite{punia2020sumerian}
\begin{itemize}
    \item Training: 8,116 parallel sentence pairs
    \item Validation: 1,015 pairs
    \item Test: 1,014 pairs
    \item Plus: 1.47M monolingual Sumerian sentences
\end{itemize}

\textbf{Egyptian-English:} EgyptianTranslation corpus \cite{fayrose2020egyptian,nasser2025hieroglyphtranslator}
\begin{itemize}
    \item Training: 10,350 parallel sentence pairs
    \item Validation: 1,293 pairs
    \item Test: 1,295 pairs
    \item Source: 150 Middle Egyptian texts (funerary, literary, historical)
\end{itemize}

\textbf{Egyptian Hieroglyphs (Vision):} Morris Franken dataset \cite{piggott2025hieroglyphs}
\begin{itemize}
    \item 18 individual hieroglyph images
    \item Labeled with Gardiner codes
    \item Format: Clean black-and-white drawings
\end{itemize}

\subsection{Models}
\label{subsec:models}

\begin{itemize}
    \item Claude Sonnet 4 (200K context, \$3/\$15 per 1M tokens)
    \item Claude Opus 4.5 (200K context, \$5/\$25 per 1M tokens)
    \item GPT-5.2 variants (128K context)
    \item Gemini 3 Pro Preview (1M context)
\end{itemize}

\subsection{Experimental Design}
\label{subsec:experimental}

\textbf{Shot settings:} 0, 1, 3, 5, 10, 20, 50, 100, 200, 500, 1000, 1500, 2000

\textbf{Prompt variants:}
\begin{itemize}
    \item Default: Expert translator persona
    \item Scribe: Ancient native scribe role-play
    \item Finkel: Dr. Irving Finkel (British Museum Assyriologist) persona
    \item Minimal: No system prompt
\end{itemize}

\textbf{Evaluation:} BLEU (primary), chrF++ (semantic), accuracy (vision), confidence distributions

\textbf{Cost optimization:} Batch APIs providing 50\% savings over standard pricing

\section{Experiments}
\label{sec:experiments}

\subsection{Sumerian Translation Learning Curves}

Comprehensive 0-2000 shot evaluation on 200 test examples established:
\begin{itemize}
    \item Logarithmic improvement pattern
    \item Peak performance at ~1000 shots (20.28 BLEU with Sonnet 4)
    \item Performance degradation beyond 1500 shots (context dilution)
    \item Persona effects: Scribe +14\% at 250-shot, diminishes at high-shot
\end{itemize}

\subsection{Egyptian Translation}

Tested on EgyptianTranslation dataset (12,938 sentences):
\begin{itemize}
    \item 100-shot: 26.73 BLEU (74\% better than Sumerian at same shot count)
    \item 1000-shot: 35.69 BLEU on full 1,295-example test set
    \item Modular prompt architecture: +0.86 BLEU improvement from language-specific prompts
\end{itemize}

\subsection{Vision-Based Hieroglyph Recognition}

Claude Sonnet 4 Vision tested on Egyptian hieroglyphs:
\begin{itemize}
    \item 0-shot: 16.7\% accuracy (1/6 correct)
    \item 5-shot: 83.3\% accuracy (5/6 correct)
    \item 10-shot: 100\% accuracy (6/6 correct, perfect performance)
\end{itemize}

\subsection{Monolingual Context Priming}

Tested prepending monolingual Sumerian sentences as context:
\begin{itemize}
    \item Strong effect at 0-shot: +37\% BLEU with 500 monolingual sentences
    \item Negligible/negative at high-shot: -5\% at 100-shot with 500 mono
    \item Finding: Unlabeled data helps when translation examples scarce
\end{itemize}

\section{Results}
\label{sec:results}

\subsection{Main Results: Multi-Language Comparison}

\begin{table}[h]
\centering
\caption{LLM In-Context Learning vs Published Baselines}
\label{tab:main_results}
\begin{tabular}{llcccl}
\toprule
Language & Family & \textbf{Our Result} & Method & Published SOTA & Status \\
\midrule
\textbf{Sumerian} & Isolate & \textbf{22.04} & In-context (1000-shot) & 21.6 \cite{punia2020sumerian} & \textbf{BEATS} ✓ \\
\textbf{Egyptian} & Afro-Asiatic & \textbf{35.69} & In-context (1000-shot) & 42.22 \cite{nasser2025hieroglyphtranslator} & 84.5\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Model:} Claude Opus 4.5 for both languages \\
\textbf{Test set:} Full test sets (1,014 Sumerian, 1,295 Egyptian)

\subsection{Vision In-Context Learning}

Egyptian hieroglyph recognition accuracy by shot count:

\begin{table}[h]
\centering
\caption{Vision-Based Hieroglyph Recognition (Claude Sonnet 4 Vision)}
\label{tab:vision_results}
\begin{tabular}{ccc}
\toprule
Shot Count & Accuracy & Correct/Total \\
\midrule
0-shot & 16.7\% & 1/6 \\
5-shot & 83.3\% & 5/6 \\
\textbf{10-shot} & \textbf{100.0\%} & \textbf{6/6} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Cross-Language Learning Patterns}

Egyptian demonstrates steeper learning curve than Sumerian:
\begin{itemize}
    \item 100-shot: Egyptian 26.73 vs Sumerian 15.35 BLEU (+74\%)
    \item 1000-shot: Egyptian 35.69 vs Sumerian 22.04 BLEU (+62\%)
    \item Hypothesis: Afro-Asiatic family connections aid in-context learning
\end{itemize}

\section{Discussion}
\label{sec:discussion}

\subsection{When In-Context Learning Beats Specialized Models}

\textbf{Sumerian success factors:}
\begin{itemize}
    \item Older baseline (2020) with simpler NMT architecture
    \item Language isolate benefits less from traditional transfer learning
    \item LLM's general reasoning may excel on unique linguistic structures
\end{itemize}

\textbf{Egyptian challenges:}
\begin{itemize}
    \item Very recent SOTA (Dec 2025) with sophisticated hierarchical pipeline
    \item Specialized components (ResNet50 glyph classifier, FSM transliteration)
    \item Trained on full 10,350 examples vs our 1,000 in-context
\end{itemize}

\subsection{Prompt Engineering Effects}

\textbf{System prompt variations:}
- Persona effects strongest at low-shot (scribe +14\% at 250-shot for Sumerian)
- Effects diminish at high-shot as massive context dominates
- Language-specific prompts provide modest gains (+0.86 BLEU for Egyptian)

\textbf{Monolingual context priming:}
- Helpful at 0-shot (+37\% with 500 monolingual Sumerian)
- Detrimental at high-shot (-5\% at 100-shot)
- Translation pairs are ~100× more valuable than monolingual text

\subsection{Cross-Modal Generalization}

Vision experiments demonstrate in-context learning generalizes beyond text:
- Perfect 10-shot accuracy on hieroglyphs
- Similar learning curve pattern (logarithmic improvement)
- Suggests frontier LLMs have general pattern recognition capabilities applicable to ancient visual systems

\section{Conclusions}
\label{sec:conclusions}

This study establishes that frontier LLMs can achieve competitive or superior performance on ancient language tasks through pure in-context learning, without any training. We demonstrate state-of-the-art on Sumerian translation, strong performance approaching SOTA on Egyptian translation, and perfect accuracy on vision-based hieroglyph recognition.

Key findings: (1) In-context learning can beat older specialized models but approaches limits against recent trained pipelines; (2) Optimal shot count is ~1000 across languages; (3) Language family affects learning efficiency (Afro-Asiatic > Isolate); (4) Monolingual context helps only when translation examples are scarce; (5) Vision capabilities match text capabilities for in-context learning.

\textbf{Future work:} Extend to additional ancient languages (Akkadian, Sanskrit, Hittite), scale vision experiments to larger datasets, investigate fine-tuning vs in-context trade-offs, and explore direct image-to-translation pipelines.

\section{Acknowledgments}
\label{sec:acknowledgments}

We thank the CDLI, Oracc, and Thesaurus Linguae Aegyptiae projects for digitizing and providing access to ancient texts. We acknowledge the creators of the EgyptianTranslation dataset and all original translators whose work enabled this research.

\bibliographystyle{plain}
\bibliography{references}

\end{document}